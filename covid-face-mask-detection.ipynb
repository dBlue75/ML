{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-02-13T14:10:34.342905Z",
     "iopub.status.busy": "2022-02-13T14:10:34.342362Z",
     "iopub.status.idle": "2022-02-13T14:10:38.654058Z",
     "shell.execute_reply": "2022-02-13T14:10:38.653461Z",
     "shell.execute_reply.started": "2022-02-13T14:10:34.342786Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T14:31:38.551044Z",
     "iopub.status.busy": "2022-02-13T14:31:38.550462Z",
     "iopub.status.idle": "2022-02-13T14:31:38.560016Z",
     "shell.execute_reply": "2022-02-13T14:31:38.559055Z",
     "shell.execute_reply.started": "2022-02-13T14:31:38.550988Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "from random import  uniform\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import InterpolationMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T14:31:39.676277Z",
     "iopub.status.busy": "2022-02-13T14:31:39.675952Z",
     "iopub.status.idle": "2022-02-13T14:31:39.680339Z",
     "shell.execute_reply": "2022-02-13T14:31:39.679279Z",
     "shell.execute_reply.started": "2022-02-13T14:31:39.676245Z"
    }
   },
   "outputs": [],
   "source": [
    "path  = \"../input/face-mask-12k-images-dataset/Face Mask Dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T14:31:46.631742Z",
     "iopub.status.busy": "2022-02-13T14:31:46.630923Z",
     "iopub.status.idle": "2022-02-13T14:31:46.764754Z",
     "shell.execute_reply": "2022-02-13T14:31:46.764136Z",
     "shell.execute_reply.started": "2022-02-13T14:31:46.631692Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = {\"image_path\":[],\"mask_status\":[],\"where\":[]}\n",
    "for where in os.listdir(path):\n",
    "    for status in os.listdir(path+\"/\"+where):\n",
    "        for image in glob.glob(path+where+\"/\"+status+\"/\"+\"*.png\"):\n",
    "            dataset[\"image_path\"].append(image)\n",
    "            dataset[\"mask_status\"].append(status)\n",
    "            dataset[\"where\"].append(where)\n",
    "dataset = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T14:31:46.766941Z",
     "iopub.status.busy": "2022-02-13T14:31:46.766429Z",
     "iopub.status.idle": "2022-02-13T14:31:46.776510Z",
     "shell.execute_reply": "2022-02-13T14:31:46.775736Z",
     "shell.execute_reply.started": "2022-02-13T14:31:46.766895Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.mask_status=dataset.mask_status.map({ 'WithMask' : 1, 'WithoutMask' : 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T14:31:50.007825Z",
     "iopub.status.busy": "2022-02-13T14:31:50.007404Z",
     "iopub.status.idle": "2022-02-13T14:31:50.021344Z",
     "shell.execute_reply": "2022-02-13T14:31:50.020187Z",
     "shell.execute_reply.started": "2022-02-13T14:31:50.007794Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T14:31:50.817796Z",
     "iopub.status.busy": "2022-02-13T14:31:50.817528Z",
     "iopub.status.idle": "2022-02-13T14:31:50.824696Z",
     "shell.execute_reply": "2022-02-13T14:31:50.823894Z",
     "shell.execute_reply.started": "2022-02-13T14:31:50.817770Z"
    }
   },
   "outputs": [],
   "source": [
    "read_image(dataset['image_path'][87]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T14:31:51.554538Z",
     "iopub.status.busy": "2022-02-13T14:31:51.553844Z",
     "iopub.status.idle": "2022-02-13T14:31:51.719788Z",
     "shell.execute_reply": "2022-02-13T14:31:51.718789Z",
     "shell.execute_reply.started": "2022-02-13T14:31:51.554500Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"With Mask: {len(dataset[dataset['mask_status']==1])},\\nWithout Mask: {len(dataset[dataset['mask_status']==0])}\\n\")\n",
    "sns.countplot(dataset[\"mask_status\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T14:31:54.499598Z",
     "iopub.status.busy": "2022-02-13T14:31:54.499320Z",
     "iopub.status.idle": "2022-02-13T14:31:55.059566Z",
     "shell.execute_reply": "2022-02-13T14:31:55.058992Z",
     "shell.execute_reply.started": "2022-02-13T14:31:54.499565Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (14,10))\n",
    "for i in range(9):\n",
    "    random = np.random.randint(1,len(dataset))\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(cv2.imread(dataset.loc[random,\"image_path\"]))\n",
    "    plt.title(dataset.loc[random, \"mask_status\"], size = 10, color = \"purple\") \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcessing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T14:32:01.470946Z",
     "iopub.status.busy": "2022-02-13T14:32:01.470653Z",
     "iopub.status.idle": "2022-02-13T14:32:01.478248Z",
     "shell.execute_reply": "2022-02-13T14:32:01.477302Z",
     "shell.execute_reply.started": "2022-02-13T14:32:01.470914Z"
    }
   },
   "outputs": [],
   "source": [
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(size=(100,100),interpolation=InterpolationMode.BILINEAR),\n",
    "    #torchvision.transforms.CenterCrop(size=(200,200)),\n",
    "    torchvision.transforms.ColorJitter(brightness=uniform(0,1), contrast=uniform(0,1), saturation=uniform(0,1), hue=uniform(0,0.5)),\n",
    "    #torchvision.transforms.RandomCrop((200, 200), fill=(0,0,0), padding_mode='edge'),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomPerspective(distortion_scale=np.random.rand(), p=0.7, fill=0),\n",
    "    torchvision.transforms.RandomRotation(degrees = int(uniform(0,180)))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T14:32:04.845552Z",
     "iopub.status.busy": "2022-02-13T14:32:04.845280Z",
     "iopub.status.idle": "2022-02-13T14:32:04.852480Z",
     "shell.execute_reply": "2022-02-13T14:32:04.851528Z",
     "shell.execute_reply.started": "2022-02-13T14:32:04.845521Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self,dataset,transform =transforms, target_transform = None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        image = read_image(self.dataset['image_path'].iloc[idx])\n",
    "        label = self.dataset['mask_status'].iloc[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T14:32:05.077685Z",
     "iopub.status.busy": "2022-02-13T14:32:05.077419Z",
     "iopub.status.idle": "2022-02-13T14:32:05.090053Z",
     "shell.execute_reply": "2022-02-13T14:32:05.089207Z",
     "shell.execute_reply.started": "2022-02-13T14:32:05.077656Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = data_utils.DataLoader(CustomImageDataset(dataset[dataset['where'] == 'Train']), batch_size=64, shuffle=True)\n",
    "test_loader = data_utils.DataLoader(CustomImageDataset(dataset[dataset['where'] == 'Test']), batch_size=64, shuffle=True)\n",
    "val_loader = data_utils.DataLoader(CustomImageDataset(dataset[dataset['where'] == 'Validation']), batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T14:32:05.091937Z",
     "iopub.status.busy": "2022-02-13T14:32:05.091575Z",
     "iopub.status.idle": "2022-02-13T14:32:05.096242Z",
     "shell.execute_reply": "2022-02-13T14:32:05.095522Z",
     "shell.execute_reply.started": "2022-02-13T14:32:05.091905Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T14:32:05.097933Z",
     "iopub.status.busy": "2022-02-13T14:32:05.097496Z",
     "iopub.status.idle": "2022-02-13T14:32:05.111146Z",
     "shell.execute_reply": "2022-02-13T14:32:05.110192Z",
     "shell.execute_reply.started": "2022-02-13T14:32:05.097897Z"
    }
   },
   "outputs": [],
   "source": [
    "class nNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(nNet,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,32,kernel_size = 1, padding = 'same',stride =1 )\n",
    "        self.conv2 = nn.Conv2d(32,64,kernel_size = 1, padding = 'same',stride =1 )\n",
    "        self.conv3 = nn.Conv2d(64,128,kernel_size = 1, padding = 'same',stride =1 )\n",
    "        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.c_drop = nn.Dropout2d()\n",
    "        \n",
    "        self.fc1 = nn.Linear(25*25*128,64)\n",
    "        self.fc2 = nn.Linear(64,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #print('input '+str(x.shape))\n",
    "        no_samples = x.shape[0]\n",
    "        x=F.relu(self.conv1(x))\n",
    "        #print('conv1 '+str(x.shape))\n",
    "        x=self.max_pool2d(x)\n",
    "        #print('maxpool1 '+str(x.shape))\n",
    "        x=F.relu(self.conv2(x))\n",
    "        #print('conv2 '+str(x.shape))\n",
    "        x=self.max_pool2d(x)\n",
    "        #print('maxpool2 '+str(x.shape))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        #print('conv3 '+str(x.shape))\n",
    "        x=x.view(64,-1)\n",
    "        #print('view '+str(x.shape))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print('fc1 '+str(x.shape))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        #print('dropout '+str(x.shape))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        #print('fc2 '+str(x.shape))\n",
    "        return F.log_softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T14:32:05.168473Z",
     "iopub.status.busy": "2022-02-13T14:32:05.168180Z",
     "iopub.status.idle": "2022-02-13T14:32:05.213800Z",
     "shell.execute_reply": "2022-02-13T14:32:05.212835Z",
     "shell.execute_reply.started": "2022-02-13T14:32:05.168444Z"
    }
   },
   "outputs": [],
   "source": [
    "model = nNet()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.001,momentum=0.05)\n",
    "train_losses , train_accuracy = [],[]\n",
    "val_losses , val_accuracy = [],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T14:32:05.216002Z",
     "iopub.status.busy": "2022-02-13T14:32:05.215707Z",
     "iopub.status.idle": "2022-02-13T14:32:05.222153Z",
     "shell.execute_reply": "2022-02-13T14:32:05.221418Z",
     "shell.execute_reply.started": "2022-02-13T14:32:05.215962Z"
    }
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T14:32:05.223712Z",
     "iopub.status.busy": "2022-02-13T14:32:05.223018Z",
     "iopub.status.idle": "2022-02-13T14:32:05.233466Z",
     "shell.execute_reply": "2022-02-13T14:32:05.232839Z",
     "shell.execute_reply.started": "2022-02-13T14:32:05.223674Z"
    }
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T14:32:05.722685Z",
     "iopub.status.busy": "2022-02-13T14:32:05.721936Z",
     "iopub.status.idle": "2022-02-13T14:32:05.730347Z",
     "shell.execute_reply": "2022-02-13T14:32:05.729261Z",
     "shell.execute_reply.started": "2022-02-13T14:32:05.722629Z"
    }
   },
   "outputs": [],
   "source": [
    "log_interval = 10\n",
    "def train_fn(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data,targets) in enumerate(train_loader):\n",
    "        if len(targets)== 64:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data.float())\n",
    "            loss=F.nll_loss(output,targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(data), len(train_loader.dataset),100. * batch_idx / len(train_loader), loss.item()))\n",
    "                train_losses.append(loss.item())\n",
    "                train_counter.append((batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "                #torch.save(network.state_dict(), '/results/model.pth')\n",
    "                #torch.save(optimizer.state_dict(), '/results/optimizer.pth')\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T14:32:06.838388Z",
     "iopub.status.busy": "2022-02-13T14:32:06.838110Z",
     "iopub.status.idle": "2022-02-13T14:32:06.846586Z",
     "shell.execute_reply": "2022-02-13T14:32:06.845773Z",
     "shell.execute_reply.started": "2022-02-13T14:32:06.838362Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_fn():\n",
    "    print('test')\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            if len(target) == 64:\n",
    "                output = model(data.float())\n",
    "                #print(\"output    \"+ str(output.shape))\n",
    "                #print(output.dtype)\n",
    "                #print(\"target     \"+ str(target.shape))\n",
    "                test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "                pred = output.data.max(1, keepdim=True)[1]\n",
    "                correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "            else:\n",
    "                continue\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(test_loader.dataset),100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T14:32:13.264959Z",
     "iopub.status.busy": "2022-02-13T14:32:13.264458Z",
     "iopub.status.idle": "2022-02-13T14:34:52.539182Z",
     "shell.execute_reply": "2022-02-13T14:34:52.538178Z",
     "shell.execute_reply.started": "2022-02-13T14:32:13.264900Z"
    }
   },
   "outputs": [],
   "source": [
    "test_fn()\n",
    "for epoch in range(1, 2):\n",
    "    train_fn(epoch)\n",
    "    test_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
